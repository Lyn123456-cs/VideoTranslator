# -*- coding: utf-8 -*-
"""
æ™ºèƒ½è¯­éŸ³è¯†åˆ«è„šæœ¬ - è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æœ€ä½³å¼•æ“
ä¼˜å…ˆä½¿ç”¨ Faster-Whisperï¼ˆå¿«5å€ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ°æ ‡å‡† Whisper
"""
import os
import subprocess
import sys

# å°è¯•å¯¼å…¥ Faster-Whisperï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ ‡å‡† Whisper
try:
    from faster_whisper import WhisperModel
    USE_FASTER = True
    print("âœ… ä½¿ç”¨ Faster-Whisperï¼ˆé€Ÿåº¦å¿«5å€ï¼‰")
except ImportError:
    import whisper
    from whisper.utils import get_writer
    USE_FASTER = False
    print("âš ï¸  ä½¿ç”¨æ ‡å‡† Whisperï¼ˆå¦‚éœ€åŠ é€Ÿï¼Œè¯·å®‰è£… faster-whisperï¼‰")

def extract_audio(input_video, audio_path="audio_tmp.wav"):
    """ä»è§†é¢‘æå–éŸ³é¢‘"""
    cmd = [
        "ffmpeg",
        "-y",
        "-i", input_video,
        "-vn",
        "-ac", "1",
        "-ar", "16000",
        "-f", "wav",
        audio_path,
    ]
    subprocess.run(cmd, check=True, capture_output=True)
    return audio_path

def format_timestamp(seconds):
    """è½¬æ¢ç§’æ•°ä¸º SRT æ—¶é—´æ ¼å¼ HH:MM:SS,mmm"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

def transcribe_with_faster_whisper(audio_path, model_size="small", output_srt="original.srt"):
    """ä½¿ç”¨ Faster-Whisper è½¬å½•"""
    print(f"åŠ è½½ Faster-Whisper æ¨¡å‹ï¼š{model_size}ï¼ˆé¦–æ¬¡å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼‰")
    
    # åŠ è½½æ¨¡å‹ - CPU ä½¿ç”¨ int8 é‡åŒ–ä»¥æé«˜é€Ÿåº¦
    model = WhisperModel(model_size, device="cpu", compute_type="int8")
    
    print("å¼€å§‹è½¬å½•éŸ³é¢‘å¹¶è‡ªåŠ¨è¯†åˆ«è¯­è¨€...")
    segments, info = model.transcribe(
        audio_path,
        task="transcribe",
        beam_size=5,
        vad_filter=True,  # å¯ç”¨ VAD è¿‡æ»¤
        vad_parameters=dict(min_silence_duration_ms=500)
    )
    
    print(f"âœ… æ£€æµ‹åˆ°è¯­è¨€: {info.language} (ç½®ä¿¡åº¦: {info.language_probability:.2f})")
    
    # è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿å¤šæ¬¡ä½¿ç”¨
    segments_list = list(segments)
    
    # å†™å…¥ SRT æ–‡ä»¶
    print(f"æ­£åœ¨å†™å…¥å­—å¹•æ–‡ä»¶: {output_srt}")
    with open(output_srt, "w", encoding="utf-8") as f:
        for i, segment in enumerate(segments_list, start=1):
            start = format_timestamp(segment.start)
            end = format_timestamp(segment.end)
            text = segment.text.strip()
            
            f.write(f"{i}\n")
            f.write(f"{start} --> {end}\n")
            f.write(f"{text}\n\n")
    
    print(f"âœ… å­—å¹•å·²ä¿å­˜åˆ°: {output_srt}")
    return output_srt

def transcribe_with_standard_whisper(audio_path, model_size="small", output_srt="original.srt"):
    """ä½¿ç”¨æ ‡å‡† Whisper è½¬å½•"""
    print(f"åŠ è½½ Whisper æ¨¡å‹ï¼š{model_size}ï¼ˆé¦–æ¬¡å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼‰")
    model = whisper.load_model(model_size)

    print("å¼€å§‹è½¬å½•éŸ³é¢‘å¹¶è‡ªåŠ¨è¯†åˆ«è¯­è¨€...")
    result = model.transcribe(audio_path, task="transcribe", verbose=True)

    print(f"âœ… æ£€æµ‹åˆ°è¯­è¨€: {result['language']}")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(output_srt)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
    
    # ä½¿ç”¨ whisper è‡ªå¸¦çš„ SRT writer
    # writerä¼šåœ¨output_dirç›®å½•ä¸‹ç”Ÿæˆä¸audio_pathåŒåçš„.srtæ–‡ä»¶
    writer = get_writer("srt", output_dir or ".")
    writer(result, audio_path, {"max_line_width": None, "max_line_count": None, "highlight_words": False})
    
    # Whisperç”Ÿæˆçš„æ–‡ä»¶ååŸºäºaudio_path
    audio_basename = os.path.basename(audio_path).replace(".wav", ".srt")
    auto_srt = os.path.join(output_dir or ".", audio_basename)
    
    # é‡å‘½ååˆ°ç›®æ ‡æ–‡ä»¶
    if os.path.exists(auto_srt):
        if auto_srt != output_srt:
            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            if os.path.exists(output_srt):
                os.remove(output_srt)
            os.rename(auto_srt, output_srt)
            print(f"âœ… å­—å¹•å·²ä¿å­˜åˆ°: {output_srt}")
        else:
            print(f"âœ… å­—å¹•å·²ä¿å­˜åˆ°: {output_srt}")
    else:
        print(f"âš ï¸  è‡ªåŠ¨ç”Ÿæˆçš„å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {auto_srt}")
        print(f"   è¾“å‡ºç›®å½•: {output_dir or '.'}")
        print(f"   audio_path: {audio_path}")
    
    return output_srt

def transcribe_audio_to_srt(audio_path, model_size="small", output_srt="original.srt"):
    """æ™ºèƒ½é€‰æ‹©è½¬å½•å¼•æ“"""
    if USE_FASTER:
        return transcribe_with_faster_whisper(audio_path, model_size, output_srt)
    else:
        return transcribe_with_standard_whisper(audio_path, model_size, output_srt)

def extract_subtitles(input_video, output_srt="original.srt", model_size="small"):
    """
    ä»è§†é¢‘ä¸­æå–å­—å¹•ï¼ˆä¾›GUIè°ƒç”¨ï¼‰
    
    Args:
        input_video: è¾“å…¥è§†é¢‘è·¯å¾„
        output_srt: è¾“å‡ºå­—å¹•è·¯å¾„
        model_size: æ¨¡å‹å¤§å°ï¼ˆtiny, base, small, medium, largeï¼‰
    
    Returns:
        bool: æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    try:
        # æå–éŸ³é¢‘
        audio_path = extract_audio(input_video)
        
        # è½¬å½•
        transcribe_audio_to_srt(audio_path, model_size, output_srt)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(audio_path):
            os.remove(audio_path)
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        return os.path.exists(output_srt)
    except Exception as e:
        print(f"âŒ è½¬å½•å¤±è´¥: {str(e)}")
        return False

def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python s1_transcribe.py <è¾“å…¥è§†é¢‘> <è¾“å‡ºå­—å¹•.srt> [æ¨¡å‹å¤§å°]")
        print("æ¨¡å‹å¤§å°: tiny, base, small, medium, large")
        sys.exit(1)

    input_video = sys.argv[1]
    output_srt = sys.argv[2]
    model_size = sys.argv[3] if len(sys.argv) > 3 else "small"

    print("=" * 60)
    print(f"ğŸ¬ VideoTranslator - å­—å¹•æå– ({'Faster-Whisper' if USE_FASTER else 'Standard Whisper'})")
    print("=" * 60)
    print(f"è¾“å…¥è§†é¢‘: {input_video}")
    print(f"è¾“å‡ºå­—å¹•: {output_srt}")
    print(f"æ¨¡å‹å¤§å°: {model_size}")
    print("=" * 60)

    # æå–éŸ³é¢‘
    print("\nğŸ“ æ­¥éª¤1: æå–éŸ³é¢‘...")
    audio_path = extract_audio(input_video)
    print(f"âœ… éŸ³é¢‘å·²æå–: {audio_path}")

    # è½¬å½•
    print(f"\nğŸ“ æ­¥éª¤2: è¯­éŸ³è¯†åˆ«...")
    transcribe_audio_to_srt(audio_path, model_size, output_srt)

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists(audio_path):
        os.remove(audio_path)
        print(f"ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {audio_path}")

    print("\nâœ… å®Œæˆï¼")

if __name__ == "__main__":
    main()
