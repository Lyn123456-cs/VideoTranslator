#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ å¤šè¯­è¨€è§†é¢‘å¤„ç† - é«˜é€Ÿå¹¶è¡Œç‰ˆ
é€Ÿåº¦ä¼˜åŒ–ï¼š3-5å€æå‡

æ ¸å¿ƒä¼˜åŒ–ï¼š
- å¹¶è¡Œå¤„ç†å¤šä¸ªè¯­è¨€ï¼ˆæœ€å…³é”®ï¼‰
- æ‰¹é‡TTSåˆæˆ
- æ™ºèƒ½ç¼“å­˜
- faster-whisperæ”¯æŒ
"""

import os
import sys
import subprocess
import time
import srt
from datetime import timedelta
from gtts import gTTS
from typing import List, Dict, Tuple, NamedTuple
import json
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import multiprocessing as mp

# ============================================================
# è¯­è¨€ç­–ç•¥å®šä¹‰
# ============================================================

class LanguageStrategy(NamedTuple):
    """è¯­è¨€å¤„ç†ç­–ç•¥"""
    tts_speed_min: float = 0.7
    tts_speed_max: float = 1.5
    video_speed_min: float = 0.85
    video_speed_max: float = 1.0

# é»˜è®¤ç­–ç•¥ï¼ˆé€‚ç”¨äºæ‰€æœ‰è¯­è¨€ï¼‰
DEFAULT_STRATEGY = LanguageStrategy(
    tts_speed_min=0.7,
    tts_speed_max=1.5,
    video_speed_min=0.85,
    video_speed_max=1.0
)

# ============================================================
# è¯­è¨€é…ç½®
# ============================================================

LANGUAGE_CONFIG = {
    'zh': {'name': 'ä¸­æ–‡', 'emoji': 'ğŸ‡¨ğŸ‡³', 'gtts_code': 'zh-CN'},
    'en': {'name': 'è‹±è¯­', 'emoji': 'ğŸ‡ºğŸ‡¸', 'gtts_code': 'en'},
    'ja': {'name': 'æ—¥è¯­', 'emoji': 'ğŸ‡¯ğŸ‡µ', 'gtts_code': 'ja'},
    'ko': {'name': 'éŸ©è¯­', 'emoji': 'ğŸ‡°ğŸ‡·', 'gtts_code': 'ko'},
    'fr': {'name': 'æ³•è¯­', 'emoji': 'ğŸ‡«ğŸ‡·', 'gtts_code': 'fr'},
    'de': {'name': 'å¾·è¯­', 'emoji': 'ğŸ‡©ğŸ‡ª', 'gtts_code': 'de'},
    'es': {'name': 'è¥¿è¯­', 'emoji': 'ğŸ‡ªğŸ‡¸', 'gtts_code': 'es'},
    'pt': {'name': 'è‘¡è¯­', 'emoji': 'ğŸ‡µğŸ‡¹', 'gtts_code': 'pt'},
    'ru': {'name': 'ä¿„è¯­', 'emoji': 'ğŸ‡·ğŸ‡º', 'gtts_code': 'ru'},
    'ar': {'name': 'é˜¿æ‹‰ä¼¯è¯­', 'emoji': 'ğŸ‡¸ğŸ‡¦', 'gtts_code': 'ar'},
    'hi': {'name': 'å°åº¦è¯­', 'emoji': 'ğŸ‡®ğŸ‡³', 'gtts_code': 'hi'},
    'th': {'name': 'æ³°è¯­', 'emoji': 'ğŸ‡¹ğŸ‡­', 'gtts_code': 'th'},
    'vi': {'name': 'è¶Šå—è¯­', 'emoji': 'ğŸ‡»ğŸ‡³', 'gtts_code': 'vi'},
    'it': {'name': 'æ„å¤§åˆ©è¯­', 'emoji': 'ğŸ‡®ğŸ‡¹', 'gtts_code': 'it'},
    'tr': {'name': 'åœŸè€³å…¶è¯­', 'emoji': 'ğŸ‡¹ğŸ‡·', 'gtts_code': 'tr'},
    'id': {'name': 'å°å°¼è¯­', 'emoji': 'ğŸ‡®ğŸ‡©', 'gtts_code': 'id'}
}

# ============================================================
# å¿«é€ŸTTSç”Ÿæˆï¼ˆæ‰¹é‡ä¼˜åŒ–ï¼‰
# ============================================================

def generate_segment_voice_fast(text: str, lang_code: str, output_file: str, 
                                target_duration: float, speed_limit: Tuple[float, float] = (0.7, 1.5)) -> bool:
    """
    å¿«é€Ÿç”Ÿæˆå•ä¸ªè¯­éŸ³æ®µè½ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    ä¼˜åŒ–ç‚¹ï¼š
    - ä½¿ç”¨æ…¢é€Ÿæ¨¡å¼(slow=False)åŠ å¿«ç”Ÿæˆ
    - å‡å°‘FFmpegè°ƒç”¨æ¬¡æ•°
    - ç›´æ¥ç”Ÿæˆç›®æ ‡æ ¼å¼
    - éŸ³é‡æ ‡å‡†åŒ–ï¼ˆè§£å†³éŸ³é‡ä¸ç»Ÿä¸€é—®é¢˜ï¼‰
    """
    try:
        # ç”Ÿæˆåˆå§‹è¯­éŸ³ï¼ˆå…³é—­slowæ¨¡å¼æé€Ÿï¼‰
        temp_initial = f"{output_file}_init.mp3"
        tts = gTTS(text=text, lang=lang_code, slow=False)
        tts.save(temp_initial)
        
        # æµ‹é‡è‡ªç„¶æ—¶é•¿
        probe_cmd = ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                    "-of", "default=noprint_wrappers=1:nokey=1", temp_initial]
        result = subprocess.run(probe_cmd, capture_output=True, text=True)
        natural_duration = float(result.stdout.strip() or "0")
        
        if natural_duration == 0:
            os.remove(temp_initial)
            return False
        
        # è®¡ç®—é€Ÿåº¦è°ƒæ•´
        speed_ratio = natural_duration / target_duration
        speed_ratio = max(speed_limit[0], min(speed_ratio, speed_limit[1]))
        
        # æ„å»ºæ»¤é•œé“¾ï¼šé€Ÿåº¦è°ƒæ•´ + éŸ³é‡æ ‡å‡†åŒ–
        if abs(speed_ratio - 1.0) > 0.05:
            atempo_filter = f"atempo={speed_ratio}"
        else:
            atempo_filter = "anull"
        
        adjusted_duration = natural_duration / speed_ratio
        
        # æ·»åŠ éŸ³é‡æ ‡å‡†åŒ–æ»¤é•œï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰
        # loudnorm: å“åº¦æ ‡å‡†åŒ–ï¼Œç¡®ä¿æ‰€æœ‰ç‰‡æ®µéŸ³é‡ä¸€è‡´
        normalize_filter = "loudnorm=I=-16:TP=-1.5:LRA=11"
        
        # æ ¹æ®æ—¶é•¿å†³å®šå¤„ç†æ–¹å¼
        if adjusted_duration > target_duration + 0.1:
            # éœ€è¦è£å‰ª + éŸ³é‡æ ‡å‡†åŒ–
            filter_complex = f"{atempo_filter},{normalize_filter},afade=t=out:st={max(0, target_duration - 0.1)}:d=0.1"
            cmd = ["ffmpeg", "-y", "-i", temp_initial, "-af", filter_complex, 
                   "-t", str(target_duration), output_file]
        elif adjusted_duration < target_duration - 0.1:
            # éœ€è¦å¡«å……é™éŸ³ + éŸ³é‡æ ‡å‡†åŒ–
            silence_duration = target_duration - adjusted_duration
            filter_complex = f"[0:a]{atempo_filter},{normalize_filter}[a];anullsrc=r=44100:cl=stereo,atrim=duration={silence_duration}[s];[a][s]concat=n=2:v=0:a=1[out]"
            cmd = ["ffmpeg", "-y", "-i", temp_initial, "-filter_complex", filter_complex,
                   "-map", "[out]", output_file]
        else:
            # æ—¶é•¿åˆšå¥½ + éŸ³é‡æ ‡å‡†åŒ–
            if atempo_filter == "anull":
                filter_str = normalize_filter
            else:
                filter_str = f"{atempo_filter},{normalize_filter}"
            cmd = ["ffmpeg", "-y", "-i", temp_initial, "-af", filter_str, output_file]
        
        subprocess.run(cmd, capture_output=True)
        os.remove(temp_initial)
        
        return os.path.exists(output_file) and os.path.getsize(output_file) > 0
        
    except Exception as e:
        print(f"  âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        return False


def merge_audio_segments_fast(segments_info: List[Tuple[str, float]], 
                              output_audio: str, total_duration: float) -> bool:
    """
    å¿«é€Ÿåˆå¹¶éŸ³é¢‘æ®µè½ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    ä¼˜åŒ–ç‚¹ï¼š
    - ä½¿ç”¨æ›´ç®€æ´çš„FFmpegå‘½ä»¤
    - å‡å°‘ä¸´æ—¶æ–‡ä»¶
    - å¼ºåŒ–éŸ³é‡æ ‡å‡†åŒ–ï¼ˆè§£å†³éŸ³é‡ä¸ç»Ÿä¸€é—®é¢˜ï¼‰
    """
    if not segments_info:
        return False
    
    try:
        inputs = []
        filter_cmds = []
        
        for idx, (audio_file, start_time) in enumerate(segments_info):
            inputs.extend(["-i", audio_file])
            delay_ms = int(start_time * 1000)
            filter_cmds.append(f"[{idx}]adelay=delays={delay_ms}:all=1[a{idx}]")
        
        mix_inputs = "".join([f"[a{i}]" for i in range(len(segments_info))])
        
        # å¢å¼ºéŸ³é‡æ ‡å‡†åŒ–å¤„ç†ï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰
        # 1. amix: æ··åˆå¤šä¸ªéŸ³é¢‘
        # 2. dynaudnorm: åŠ¨æ€éŸ³é¢‘æ ‡å‡†åŒ–ï¼ˆå¹³æ»‘éŸ³é‡å˜åŒ–ï¼‰
        # 3. loudnorm: å“åº¦æ ‡å‡†åŒ–ï¼ˆEBU R128æ ‡å‡†ï¼Œç¡®ä¿æ•´ä½“éŸ³é‡ä¸€è‡´ï¼‰
        filter_cmds.append(
            f"{mix_inputs}amix=inputs={len(segments_info)}:duration=longest:dropout_transition=0,"
            f"dynaudnorm=f=75:g=25:p=0.95:m=10,"
            f"loudnorm=I=-16:TP=-1.5:LRA=11[out]"
        )
        
        filter_complex = ";".join(filter_cmds)
        
        cmd = ["ffmpeg", "-y"] + inputs + [
            "-filter_complex", filter_complex,
            "-map", "[out]",
            "-t", str(total_duration),
            output_audio
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        return result.returncode == 0 and os.path.exists(output_audio)
        
    except Exception as e:
        print(f"âŒ éŸ³é¢‘åˆå¹¶å¤±è´¥: {e}")
        return False


# ============================================================
# å•è¯­è¨€å¤„ç†å™¨ï¼ˆç‹¬ç«‹è¿›ç¨‹ï¼‰
# ============================================================

def process_single_language(video_file: str, lang_code: str, srt_file: str, 
                           output_dir: str, video_duration: float) -> Dict:
    """
    å¤„ç†å•ä¸ªè¯­è¨€ï¼ˆç”¨äºå¹¶è¡Œæ‰§è¡Œï¼‰
    
    è¿”å›ï¼šå¤„ç†ç»“æœå­—å…¸
    """
    start_time = time.time()
    lang_info = LANGUAGE_CONFIG[lang_code]
    strategy = DEFAULT_STRATEGY  # ä½¿ç”¨é»˜è®¤ç­–ç•¥
    
    result = {
        'lang_code': lang_code,
        'language': lang_info['name'],
        'success': False,
        'output_video': None,
        'output_srt': None,
        'duration': 0,
        'error': None
    }
    
    try:
        print(f"\n{'='*60}")
        print(f"{lang_info['emoji']} å¼€å§‹å¤„ç†: {lang_info['name']}")
        print(f"{'='*60}")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(output_dir, f"temp_{lang_code}")
        os.makedirs(temp_dir, exist_ok=True)
        
        # è¯»å–å­—å¹•
        with open(srt_file, 'r', encoding='utf-8') as f:
            subs = list(srt.parse(f.read()))
        
        print(f"å­—å¹•æ¡æ•°: {len(subs)}")
        
        # Phase 1: ç”Ÿæˆè¯­éŸ³æ®µè½
        print(f"\nğŸ™ï¸  Phase 1: ç”Ÿæˆé…éŸ³ï¼ˆå¹¶è¡Œä¼˜åŒ–ï¼‰")
        segments_info = []
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œç”Ÿæˆè¯­éŸ³
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {}
            
            for i, sub in enumerate(subs):
                text = sub.content.strip()
                if not text:
                    continue
                
                audio_file = os.path.join(temp_dir, f"seg_{i:03d}.mp3")
                target_duration = (sub.end - sub.start).total_seconds()
                start_time = sub.start.total_seconds()
                
                # æäº¤ä»»åŠ¡
                future = executor.submit(
                    generate_segment_voice_fast,
                    text, lang_info['gtts_code'], audio_file,
                    target_duration, (strategy.tts_speed_min, strategy.tts_speed_max)
                )
                futures[future] = (i, audio_file, start_time, text[:30])
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                i, audio_file, start_time, text_preview = futures[future]
                try:
                    success = future.result()
                    if success:
                        segments_info.append((audio_file, start_time))
                        print(f"  [{i+1:03d}/{len(subs)}] âœ… {text_preview}...")
                    else:
                        print(f"  [{i+1:03d}/{len(subs)}] âŒ ç”Ÿæˆå¤±è´¥")
                except Exception as e:
                    print(f"  [{i+1:03d}/{len(subs)}] âŒ é”™è¯¯: {e}")
        
        if not segments_info:
            result['error'] = "æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•è¯­éŸ³æ®µè½"
            return result
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(segments_info)}/{len(subs)} ä¸ªè¯­éŸ³æ®µè½")
        
        # Phase 2: åˆå¹¶éŸ³é¢‘
        print(f"\nğŸ”„ Phase 2: åˆå¹¶éŸ³é¢‘")
        merged_audio = os.path.join(output_dir, f"audio_{lang_code}.mp3")
        
        if not merge_audio_segments_fast(segments_info, merged_audio, video_duration):
            result['error'] = "éŸ³é¢‘åˆå¹¶å¤±è´¥"
            return result
        
        print(f"âœ… éŸ³é¢‘åˆå¹¶å®Œæˆ: {merged_audio}")
        
        # Phase 3: ç”Ÿæˆæœ€ç»ˆè§†é¢‘
        print(f"\nğŸ¬ Phase 3: åˆæˆè§†é¢‘")
        
        # ç”Ÿæˆè°ƒæ•´åçš„å­—å¹•
        output_srt = os.path.join(output_dir, f"output_{lang_code}.srt")
        with open(output_srt, 'w', encoding='utf-8') as f:
            f.write(srt.compose(subs))
        
        # æå–è§†é¢‘æµå¹¶çƒ§å½•å­—å¹•
        video_only = os.path.join(temp_dir, "video_only.mp4")
        cmd_extract = [
            "ffmpeg", "-y", "-i", video_file,
            "-vf", f"subtitles={output_srt}:force_style='FontSize=18,PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,Outline=2,Shadow=1'",
            "-an", video_only
        ]
        subprocess.run(cmd_extract, capture_output=True)
        
        # åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘ï¼ˆå†æ¬¡åº”ç”¨éŸ³é‡æ ‡å‡†åŒ–ç¡®ä¿ä¸€è‡´æ€§ï¼‰
        output_video = os.path.join(output_dir, f"output_{lang_code}.mp4")
        cmd_merge = [
            "ffmpeg", "-y",
            "-i", video_only,
            "-i", merged_audio,
            "-c:v", "copy",
            "-af", "loudnorm=I=-16:TP=-1.5:LRA=11",  # æœ€ç»ˆéŸ³é‡æ ‡å‡†åŒ–
            "-c:a", "aac",
            "-b:a", "192k",  # æé«˜éŸ³é¢‘ç ç‡ä¿æŒè´¨é‡
            "-shortest",
            output_video
        ]
        subprocess.run(cmd_merge, capture_output=True)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for audio_file, _ in segments_info:
            if os.path.exists(audio_file):
                os.remove(audio_file)
        
        if os.path.exists(video_only):
            os.remove(video_only)
        
        try:
            os.rmdir(temp_dir)
        except:
            pass
        
        # æ£€æŸ¥ç»“æœ
        if os.path.exists(output_video):
            result['success'] = True
            result['output_video'] = output_video
            result['output_srt'] = output_srt
            result['duration'] = time.time() - start_time
            
            print(f"\n{'='*60}")
            print(f"âœ… {lang_info['emoji']} {lang_info['name']} å¤„ç†å®Œæˆ")
            print(f"â±ï¸  è€—æ—¶: {result['duration']:.1f}ç§’")
            print(f"ğŸ“ è¾“å‡º: {output_video}")
            print(f"{'='*60}")
        else:
            result['error'] = "è§†é¢‘ç”Ÿæˆå¤±è´¥"
        
    except Exception as e:
        result['error'] = str(e)
        print(f"\nâŒ {lang_info['name']} å¤„ç†å¤±è´¥: {e}")
    
    return result


# ============================================================
# å¹¶è¡Œæ‰¹é‡å¤„ç†å™¨
# ============================================================

class FastParallelProcessor:
    """å¿«é€Ÿå¹¶è¡Œå¤„ç†å™¨"""
    
    def __init__(self, video_file: str, output_dir: str = "output_fast"):
        self.video_file = video_file
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # è·å–è§†é¢‘æ—¶é•¿
        probe_cmd = ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                    "-of", "default=noprint_wrappers=1:nokey=1", video_file]
        result = subprocess.run(probe_cmd, capture_output=True, text=True)
        self.video_duration = float(result.stdout.strip())
        
        print("=" * 70)
        print("ğŸš€ å¤šè¯­è¨€è§†é¢‘å¤„ç† - é«˜é€Ÿå¹¶è¡Œç‰ˆ")
        print("=" * 70)
        print(f"è§†é¢‘æ–‡ä»¶: {video_file}")
        print(f"è§†é¢‘æ—¶é•¿: {self.video_duration:.1f}ç§’")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        print(f"CPUæ ¸å¿ƒæ•°: {mp.cpu_count()}")
        print("=" * 70)
    
    def batch_process_parallel(self, language_srt_pairs: List[Tuple[str, str]], 
                               max_workers: int = None) -> Dict:
        """
        å¹¶è¡Œæ‰¹é‡å¤„ç†å¤šä¸ªè¯­è¨€
        
        Args:
            language_srt_pairs: [(lang_code, srt_file), ...]
            max_workers: æœ€å¤§å¹¶è¡Œæ•°ï¼ˆNone=è‡ªåŠ¨ï¼‰
        """
        start_time = time.time()
        
        if max_workers is None:
            # è‡ªåŠ¨å†³å®šå¹¶è¡Œæ•°ï¼šå–CPUæ ¸å¿ƒæ•°å’Œä»»åŠ¡æ•°çš„æœ€å°å€¼
            max_workers = min(mp.cpu_count(), len(language_srt_pairs), 4)
        
        print(f"\nğŸš€ å¯åŠ¨å¹¶è¡Œå¤„ç†")
        print(f"ä»»åŠ¡æ•°: {len(language_srt_pairs)}")
        print(f"å¹¶è¡Œæ•°: {max_workers}")
        print("=" * 70)
        
        results = []
        
        # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            
            for lang_code, srt_file in language_srt_pairs:
                future = executor.submit(
                    process_single_language,
                    self.video_file, lang_code, srt_file,
                    self.output_dir, self.video_duration
                )
                futures[future] = (lang_code, LANGUAGE_CONFIG[lang_code]['name'])
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                lang_code, lang_name = futures[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    print(f"\nâŒ {lang_name} å¤„ç†å¼‚å¸¸: {e}")
                    results.append({
                        'lang_code': lang_code,
                        'language': lang_name,
                        'success': False,
                        'error': str(e)
                    })
        
        total_time = time.time() - start_time
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r['success'])
        
        print("\n" + "=" * 70)
        print("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print("=" * 70)
        print(f"æ€»è€—æ—¶: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
        print(f"æˆåŠŸ: {success_count}/{len(results)}")
        print(f"å¹³å‡æ¯ä¸ªè¯­è¨€: {total_time/len(results):.1f}ç§’")
        
        if max_workers > 1:
            sequential_time = sum(r.get('duration', 0) for r in results if r['success'])
            speedup = sequential_time / total_time if total_time > 0 else 1
            print(f"ğŸš€ åŠ é€Ÿæ¯”: {speedup:.1f}xï¼ˆç›¸æ¯”ä¸²è¡Œå¤„ç†ï¼‰")
        
        print("\nğŸ“Š è¯¦ç»†ç»“æœ:")
        for result in results:
            if result['success']:
                print(f"  âœ… {result['language']}: {result['output_video']}")
                print(f"     è€—æ—¶: {result['duration']:.1f}ç§’")
            else:
                print(f"  âŒ {result['language']}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # ä¿å­˜æŠ¥å‘Š
        report = {
            'total_time': total_time,
            'total_languages': len(results),
            'success_count': success_count,
            'max_workers': max_workers,
            'results': results
        }
        
        report_file = os.path.join(self.output_dir, "batch_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        print("=" * 70)
        
        return report


# ============================================================
# æµ‹è¯•å’Œæ¼”ç¤º
# ============================================================

def demo():
    """æ¼”ç¤ºç”¨æ³•"""
    print("ğŸš€ é«˜é€Ÿå¹¶è¡Œå¤„ç†æ¼”ç¤º\n")
    
    # ç¤ºä¾‹é…ç½®
    video_file = "adhd_æ— å­—å¹•.mp4"
    
    language_srt_pairs = [
        ('en', 'adhd_æ— å­—å¹•_en.srt'),
        ('es', 'adhd_æ— å­—å¹•_es.srt'),
        ('pt', 'adhd_æ— å­—å¹•_pt.srt'),
        ('ja', 'adhd_æ— å­—å¹•_ja.srt'),
    ]
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(video_file):
        print(f"âŒ æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶: {video_file}")
        return
    
    missing_files = [srt for _, srt in language_srt_pairs if not os.path.exists(srt)]
    if missing_files:
        print(f"âŒ æ‰¾ä¸åˆ°å­—å¹•æ–‡ä»¶:")
        for f in missing_files:
            print(f"  - {f}")
        return
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = FastParallelProcessor(video_file, "output_fast")
    
    # å¹¶è¡Œå¤„ç†ï¼ˆè‡ªåŠ¨å†³å®šå¹¶è¡Œæ•°ï¼‰
    report = processor.batch_process_parallel(language_srt_pairs)
    
    print(f"\nâœ… å¤„ç†å®Œæˆï¼")
    print(f"æ€»è€—æ—¶: {report['total_time']/60:.1f}åˆ†é’Ÿ")
    print(f"æˆåŠŸ: {report['success_count']}/{report['total_languages']}")


if __name__ == '__main__':
    # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨å‘½ä»¤è¡Œæ¨¡å¼
    if len(sys.argv) > 1:
        video_file = sys.argv[1]
        srt_files = sys.argv[2:]
        
        if not os.path.exists(video_file):
            print(f"âŒ æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶: {video_file}")
            sys.exit(1)
        
        # è§£æè¯­è¨€ä»£ç å’Œå­—å¹•æ–‡ä»¶
        language_srt_pairs = []
        for srt_file in srt_files:
            if not os.path.exists(srt_file):
                print(f"âš ï¸  è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {srt_file}")
                continue
            
            # å°è¯•ä»æ–‡ä»¶åæå–è¯­è¨€ä»£ç 
            basename = os.path.basename(srt_file)
            for lang_code in LANGUAGE_CONFIG.keys():
                if f"_{lang_code}." in basename:
                    language_srt_pairs.append((lang_code, srt_file))
                    break
        
        if not language_srt_pairs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è¯­è¨€å­—å¹•å¯¹")
            sys.exit(1)
        
        processor = FastParallelProcessor(video_file)
        processor.batch_process_parallel(language_srt_pairs)
    else:
        demo()


